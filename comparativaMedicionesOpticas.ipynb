{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFM_Final_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BASE"
      ],
      "metadata": {
        "id": "SoB3t9Uzp75e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar paquetes que serán usados\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import linear_model, datasets\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from collections import Counter\n",
        "from warnings import filterwarnings\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import imblearn\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Definicion del color para las gráficas\n",
        "paleta=sns.color_palette(\"Blues_r\")\n",
        "\n",
        "# Lectura del conjunto de datos\n",
        "conjunto_datos = pd.read_csv(\"/content/drive/MyDrive/conjunto_1.csv\", sep=\";\", decimal=\",\")\n",
        "\n",
        "# Se renombran las columnas para que sean más descriptivas\n",
        "conjunto_datos.columns = [\"FS365\", \"FS450\", \"LDF35\",\"LDF42\",\"Clases\"]\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Función para la creacion del conjunto usando la técnica de sobremuestreo\n",
        "Parametros:   X_trains: matriz con el conjunto de entrenamiento\n",
        "              y_trains: vector con las clases objetivo\n",
        "Retorna: El conjunto con las clases balanceadas usando la técnica de sobremuestreo\n",
        "\"\"\"\n",
        "def genera_sobremuestreo(X_trains,y_trains):\n",
        "  conjunto_entrenamiento = pd.concat([X_trains, y_trains], axis=1) \n",
        "  cuenta_clases = conjunto_entrenamiento.Clases.value_counts()\n",
        "\n",
        "  cant_clase_0 = cuenta_clases[0]\n",
        "  cant_clase_1 = cuenta_clases[1]\n",
        "  cant_clase_2 = cuenta_clases[2]\n",
        "\n",
        "  conjunto_clase_0 = conjunto_entrenamiento[conjunto_entrenamiento['Clases'] == 0]\n",
        "  conjunto_clase_1 = conjunto_entrenamiento[conjunto_entrenamiento['Clases'] == 1]\n",
        "  conjunto_clase_2 = conjunto_entrenamiento[conjunto_entrenamiento['Clases'] == 2]\n",
        "\n",
        "  conjunto_clase_2_sm = conjunto_clase_2.sample(cant_clase_1, replace=True)\n",
        "  conjunto_clase_0_sm = conjunto_clase_0.sample(cant_clase_1, replace=True)\n",
        "\n",
        "  conjunto_sm = pd.concat([conjunto_clase_1, conjunto_clase_2_sm, conjunto_clase_0_sm], axis=0)\n",
        "  conjunto_sm.groupby('Clases').size()\n",
        "  return conjunto_sm\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Función para la creacion del conjunto usando la técnica de SMOTE\n",
        "Parametros:   X_trainm: matriz con el conjunto de entrenamiento\n",
        "              y_trainm: vector con las clases objetivo\n",
        "Retorna: El conjunto con las clases balanceadas usando la técnica de SMOTE\n",
        "\"\"\"\n",
        "def genera_smote(X_trainm,y_trainm):\n",
        "  sobre_muestreo_smote = SMOTE()\n",
        "  X, y = sobre_muestreo_smote.fit_resample(X_trainm, y_trainm)\n",
        "\n",
        "  conjunto_smo = pd.concat([X, y], axis=1)\n",
        "  conjunto_smo.groupby('Clases').size()\n",
        "  return conjunto_smo\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Función que realiza el entrenamiento con el conjunto original creado para tal fin\n",
        "Parametros:   algoritmo: es el modelo o algoritmos que se va a entrenar\n",
        "              parametros: hiperparámetros del modelo\n",
        "              X_traino, y_traino: conjunto de entrenamiento\n",
        "Salida por pantalla 1: los mejores hiperparámetros posterior al entrenamiento con GridSearchCV\n",
        "Salida por pantalla 2: puntuación generada por GridSearchCV\n",
        "\"\"\"\n",
        "def entrena_original(algoritmo, parametros, X_traino, y_traino):\n",
        "  print(\"\\n\\n  Conjunto Original\")\n",
        "  gs = GridSearchCV(algoritmo, parametros, cv=3, n_jobs=-1, verbose=True)\n",
        "  mejores_parametros = gs.fit(X_traino, y_traino)\n",
        "  print(mejores_parametros.best_estimator_)\n",
        "  print(mejores_parametros.best_score_)\n",
        "\n",
        "\"\"\"\n",
        "Función que realiza el entrenamiento con el conjunto de Sobremuestreo\n",
        "Parametros:   algoritmo: es el modelo o algoritmos que se va a entrenar\n",
        "              parametros: hiperparámetros del modelo\n",
        "              conjunto_sm: es el conjunto de entrenamiento, con las clases balanceadas \n",
        "                                      usando la técnica de sobremuestreo\n",
        "Salida por pantalla 1: los mejores hiperparámetros posterior al entrenamiento con GridSearchCV\n",
        "Salida por pantalla 2: puntuación generada por GridSearchCV\n",
        "\"\"\"\n",
        "def entrena_sobremuestreo(algoritmo, parametros, conjunto_sm):\n",
        "  print(\"\\n\\n  Conjunto Sobremuestreo\")\n",
        "  X_train_csm = conjunto_sm.drop('Clases', axis = 'columns')\n",
        "  y_train_csm = conjunto_sm['Clases']\n",
        "  gs = GridSearchCV(algoritmo, parametros, cv=3, n_jobs=-1, verbose=True)\n",
        "  mejores_parametros = gs.fit(X_train_csm, y_train_csm)\n",
        "  print(mejores_parametros.best_estimator_)\n",
        "  print(mejores_parametros.best_score_)\n",
        "\n",
        "\"\"\"\n",
        "Función que realiza el entrenamiento con el conjunto de SMOTE\n",
        "Parametros:   algoritmo: es el modelo o algoritmos que se va a entrenar\n",
        "              parametros: hiperparámetros del modelo\n",
        "              conjunto_smo: es el conjunto de entrenamiento, con las clases balanceadas \n",
        "                                      usando la técnica de SMOTE\n",
        "Salida por pantalla 1: los mejores hiperparámetros posterior al entrenamiento con GridSearchCV\n",
        "Salida por pantalla 2: puntuación generada por GridSearchCV\n",
        "\"\"\"\n",
        "def entrena_smote(algoritmo, parametros, conjunto_smo): \n",
        "  print(\"\\n\\n  Conjunto SMOTE \")\n",
        "  X_train_smo = conjunto_smo.drop('Clases', axis = 'columns')\n",
        "  y_train_smo = conjunto_smo['Clases']\n",
        "  gs = GridSearchCV(algoritmo, parametros, cv=3, n_jobs=-1, verbose=True)\n",
        "  mejores_parametros = gs.fit(X_train_smo, y_train_smo)\n",
        "  print(mejores_parametros.best_estimator_)\n",
        "  print(mejores_parametros.best_score_)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Función que realiza el reentrenamiento del modelo, lo evalúa y genera métricas\n",
        "Parametros:   conjunto_entrenamiento, X_test_x, y_test_x: conjuntos de entrenamiento y pruebas\n",
        "              algoritmo:  es el modelo que se va a entrenar, ya tiene los hiperparámetros la instanciar el clasificador\n",
        "              titulo:  hace referencia al tipo de set de entrenamiento, puede ser \"Original\", \"Sobremuestreo\" o \"SMOTE\"\n",
        "Salida por pantalla 1: métrica de precision\n",
        "Salida por pantalla 2: métrica de exactitud\n",
        "Salida por pantalla 3: informe con las principales métricas de clasificación.\n",
        "Salida por pantalla 4: matriz de confusión\n",
        "\"\"\"\n",
        "def genera_graficas(conjunto_entrenamiento, X_test_x, y_test_x, algoritmo, titulo):\n",
        "\n",
        "  X_train_x = conjunto_entrenamiento.drop('Clases', axis = 'columns')\n",
        "  y_train_x = conjunto_entrenamiento['Clases']\n",
        "\n",
        "  algoritmo.fit(X_train_x, y_train_x)\n",
        "  y_pred = algoritmo.predict(X_test_x)\n",
        "\n",
        "  print(\"Precision: \",precision_score(y_test_x, y_pred, average='weighted',zero_division=False))\n",
        "  print(\"Exactitud: \",accuracy_score(y_test_x, y_pred))\n",
        "\n",
        "  print(classification_report(y_test_x, y_pred,zero_division=False))\n",
        "  matriz_confusion = confusion_matrix(y_test_x, y_pred)\n",
        "\n",
        "  plt.figure(figsize=(7,7))\n",
        "  sns.heatmap(matriz_confusion, annot=True, cmap=paleta, linecolor='white', linewidths=0.1, square=True)\n",
        "  plt.title(titulo,size=16)\n",
        "  plt.xlabel('Etiqueta Predicha',size=14)\n",
        "  plt.ylabel('Etiqueta Verdadera',size=14)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "# División del conjunto de datos, en subconjuntos de entrenamiento y pruebas\n",
        "X_train, X_test, y_train, y_test = train_test_split(conjunto_datos.drop('Clases', axis = 'columns'), \n",
        "    conjunto_datos['Clases'],train_size= 0.7,random_state = 42,shuffle= True)\n",
        "\n",
        "# Une la matriz y vector de entrenamiento en un mismo conjunto\n",
        "conjunto_original = pd.concat([X_train, y_train], axis=1)\n",
        "\n",
        "# Generación de los conjuntos de entrenamiento, con las clases balanceadas usando _\n",
        "# las técnicas de Sobremuestreo y SMOTE\n",
        "conjunto_sobremuestreo = genera_sobremuestreo(X_train,y_train) \n",
        "conjunto_smote = genera_smote(X_train, y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "0qcOkJgwp9wV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento"
      ],
      "metadata": {
        "id": "pgoqwKS_Vlc1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regresión Logística"
      ],
      "metadata": {
        "id": "tew4er3Bwlb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Inicio el clasificador Regesion Logística\n",
        "clasificador_reglog = LogisticRegression(random_state=42)  \n",
        "\n",
        "# Se establecen los hiperparámetros del clasificador Regesion Logística\n",
        "hiper_parametros = {}                                     \n",
        "hiper_parametros['classifier__penalty'] = ['l1', 'l2']\n",
        "hiper_parametros['classifier__C'] = [10**-2, 10**-1, 10**0, 10**1, 10**2]\n",
        "hiper_parametros['classifier__solver'] = ['liblinear','lbfgs','newton-cg','sag','saga']\n",
        "hiper_parametros['classifier'] = [clasificador_reglog]\n",
        "pipeline = Pipeline([('classifier', clasificador_reglog)])\n",
        "filterwarnings('ignore')\n",
        "\n",
        "# Se realiza entrenamiento del modelo usando GridSearchCV\n",
        "entrena_original(pipeline, hiper_parametros, X_train, y_train)  \n",
        "entrena_sobremuestreo(pipeline, hiper_parametros, conjunto_sobremuestreo)  \n",
        "entrena_smote(pipeline, hiper_parametros, conjunto_smote)  \n"
      ],
      "metadata": {
        "id": "eMTTkUFvwqgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN"
      ],
      "metadata": {
        "id": "RTRvji_Fyh4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicio del clasificador K-Vecinos más Cercanos \n",
        "clasificador_veccer = KNeighborsClassifier()                \n",
        "\n",
        "# Se establecen los hiperparámetros del clasificador K-Vecinos más Cercanos   \n",
        "hiper_parametros = {}                                     \n",
        "hiper_parametros['classifier__n_neighbors'] = [5,10,20,50]\n",
        "hiper_parametros['classifier__weights'] = ['uniform', 'distance']\n",
        "hiper_parametros['classifier__leaf_size'] = [20,40,1]\n",
        "hiper_parametros['classifier__p'] = [1,2]\n",
        "hiper_parametros['classifier__algorithm'] = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "hiper_parametros['classifier__metric'] = ['minkowski', 'chebyshev']\n",
        "hiper_parametros['classifier'] = [clasificador_veccer]   \n",
        "pipeline = Pipeline([('classifier', clasificador_veccer)])\n",
        "filterwarnings('ignore')\n",
        "\n",
        "# Se realiza entrenamiento del modelo usando GridSearchCV\n",
        "entrena_original(pipeline, hiper_parametros, X_train, y_train)  \n",
        "entrena_sobremuestreo(pipeline, hiper_parametros, conjunto_sobremuestreo)  \n",
        "entrena_smote(pipeline, hiper_parametros, conjunto_smote)  "
      ],
      "metadata": {
        "id": "-_jTqHu5yiwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVMs"
      ],
      "metadata": {
        "id": "0v7YJ99dyjFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicio del clasificador Máquina de Soporte de Vectores\n",
        "clasificador_maqsop = SVC(random_state=42)              \n",
        "\n",
        "# Se establecen los hiperparámetros del clasificador Máquina de Soporte de Vectores\n",
        "hiper_parametros = {}                                      \n",
        "hiper_parametros['classifier__C'] = [0.1,1, 10, 100] \n",
        "hiper_parametros['classifier__gamma'] = [1,0.1,0.01,0.001]\n",
        "hiper_parametros['classifier__kernel'] = ['rbf', 'poly', 'sigmoid']\n",
        "hiper_parametros['classifier__degree'] = [0, 1, 2, 3, 4, 5, 6]\n",
        "hiper_parametros['classifier'] = [clasificador_maqsop]   \n",
        "pipeline = Pipeline([('classifier', clasificador_maqsop)])\n",
        "filterwarnings('ignore')\n",
        "\n",
        "# Se realiza entrenamiento del modelo usando GridSearchCV\n",
        "entrena_original(pipeline, hiper_parametros, X_train, y_train)  \n",
        "entrena_sobremuestreo(pipeline, hiper_parametros, conjunto_sobremuestreo)  \n",
        "entrena_smote(pipeline, hiper_parametros, conjunto_smote)  "
      ],
      "metadata": {
        "id": "tHX0Z1-QyjUZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "e4e022bf-36a3-43a5-9d07-4010f74a619c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "  Conjunto Original\n",
            "Fitting 3 folds for each of 336 candidates, totalling 1008 fits\n",
            "Pipeline(steps=[('classifier',\n",
            "                 SVC(C=10, degree=0, gamma=0.1, random_state=42))])\n",
            "0.8025451559934318\n",
            "\n",
            "\n",
            "  Conjunto Sobremuestreo\n",
            "Fitting 3 folds for each of 336 candidates, totalling 1008 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f8767233f311>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Se realiza entrenamiento del modelo usando GridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mentrena_original\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiper_parametros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mentrena_sobremuestreo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiper_parametros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconjunto_sobremuestreo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mentrena_smote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiper_parametros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconjunto_smote\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-1ce340fcd339>\u001b[0m in \u001b[0;36mentrena_sobremuestreo\u001b[0;34m(algoritmo, parametros, conjunto_sm)\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0my_train_csm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconjunto_sm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Clases'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgoritmo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparametros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m   \u001b[0mmejores_parametros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_csm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_csm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmejores_parametros\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmejores_parametros\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes"
      ],
      "metadata": {
        "id": "iNfY--GJyjiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicio del clasificador Naive Bayes\n",
        "clasificador_naibay = GaussianNB()                        \n",
        "\n",
        "# Se establecen los hiperparámetros del clasificador Naive Bayes\n",
        "hiper_parametros = {}                                      \n",
        "hiper_parametros['classifier__var_smoothing'] = np.logspace(0,-9, num=100)\n",
        "hiper_parametros['classifier'] = [clasificador_naibay]\n",
        "pipeline = Pipeline([('classifier', clasificador_naibay)])\n",
        "filterwarnings('ignore')\n",
        "\n",
        "# Se realiza entrenamiento del modelo usando GridSearchCV\n",
        "entrena_original(pipeline, hiper_parametros, X_train, y_train)  \n",
        "entrena_sobremuestreo(pipeline, hiper_parametros, conjunto_sobremuestreo)  \n",
        "entrena_smote(pipeline, hiper_parametros, conjunto_smote)  "
      ],
      "metadata": {
        "id": "f6cgOnYxyjtE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15b6087c-d8f6-4f0d-9330-c5ec4f6b7982"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "  Conjunto Original\n",
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
            "Pipeline(steps=[('classifier',\n",
            "                 GaussianNB(var_smoothing=0.0012328467394420659))])\n",
            "0.8136288998357964\n",
            "\n",
            "\n",
            "  Conjunto Sobremuestreo\n",
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
            "Pipeline(steps=[('classifier',\n",
            "                 GaussianNB(var_smoothing=0.0015199110829529332))])\n",
            "0.8652482269503546\n",
            "\n",
            "\n",
            "  Conjunto SMOTE \n",
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
            "Pipeline(steps=[('classifier',\n",
            "                 GaussianNB(var_smoothing=0.0003511191734215131))])\n",
            "0.8723404255319149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Redes Neuronales"
      ],
      "metadata": {
        "id": "-rsnJU_Pyj6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicio del clasificador Redes Neuronales\n",
        "clasificador_redneu = MLPClassifier(random_state=42)  \n",
        "\n",
        "# Se establecen los hiperparámetros del clasificador Redes Neuronales\n",
        "hiper_parametros = {}                                     \n",
        "hiper_parametros['classifier__alpha'] = [0.1, 0.01, 0.001]\n",
        "hiper_parametros['classifier__max_iter'] = [5,10,20]\n",
        "hiper_parametros['classifier__batch_size'] = [2,5,20]\n",
        "hiper_parametros['classifier__activation'] = ['identity', 'logistic', 'tanh', 'relu']\n",
        "hiper_parametros['classifier__hidden_layer_sizes'] = [1,3,5,10,50]  \n",
        "hiper_parametros['classifier'] = [clasificador_redneu]\n",
        "pipeline = Pipeline([('classifier', clasificador_redneu)])\n",
        "filterwarnings('ignore')\n",
        "\n",
        "# Se realiza entrenamiento del modelo usando GridSearchCV\n",
        "entrena_original(pipeline, hiper_parametros, X_train, y_train)  \n",
        "entrena_sobremuestreo(pipeline, hiper_parametros, conjunto_sobremuestreo)  \n",
        "entrena_smote(pipeline, hiper_parametros, conjunto_smote)   "
      ],
      "metadata": {
        "id": "LTOXW8xxykFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reentrenamiento y evaluación de modelos"
      ],
      "metadata": {
        "id": "SU3Fez3V7UMu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El código que se encuentra en la parte inferior, cuenta con los hiperparámetros que mejores resultados proporcionaron al realizar el entrenamiento con GridSearchCV. Es posible que haya una variación, y se debe revisar las salidas por pantalla de la sección \"Entrenamiento\"."
      ],
      "metadata": {
        "id": "iryvLdeWUhbM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regresión Logística"
      ],
      "metadata": {
        "id": "Z9TpxpW1CIpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n************ Original ************\\n\")\n",
        "clasificador = LogisticRegression(C=10, penalty='l1', random_state=42,solver='liblinear')\n",
        "genera_graficas(conjunto_original, X_test, y_test, clasificador, \"Original\") \n",
        "\n",
        "print(\"\\n************ Sobremuestreo ************\\n\")\n",
        "clasificador = LogisticRegression(C=1, random_state=42)\n",
        "genera_graficas(conjunto_sobremuestreo, X_test, y_test, clasificador,\"Sobremuestreo\") \n",
        "\n",
        "print(\"\\n************ SMOTE ************\\n\")\n",
        "clasificador = LogisticRegression(C=10, random_state=42)\n",
        "genera_graficas(conjunto_smote, X_test, y_test, clasificador, \"SMOTE\") "
      ],
      "metadata": {
        "id": "hyuQtJhT7p1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN"
      ],
      "metadata": {
        "id": "jQBjyepZCAgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n************ Original ************\\n\")\n",
        "clasificador = KNeighborsClassifier(leaf_size=20, n_neighbors=10, p=1)\n",
        "genera_graficas(conjunto_original, X_test, y_test, clasificador, \"Original\") \n",
        "\n",
        "print(\"\\n************ Sobremuestreo ************\\n\")\n",
        "clasificador = KNeighborsClassifier(leaf_size=20, n_neighbors=10, p=1, weights='distance')\n",
        "genera_graficas(conjunto_sobremuestreo, X_test, y_test, clasificador,\"Sobremuestreo\") \n",
        "\n",
        "print(\"\\n************ SMOTE ************\\n\")\n",
        "clasificador = KNeighborsClassifier(leaf_size=20, n_neighbors=10, p=1, weights='distance')\n",
        "genera_graficas(conjunto_smote, X_test, y_test, clasificador, \"SMOTE\") "
      ],
      "metadata": {
        "id": "WtTCF31jCRfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVMs"
      ],
      "metadata": {
        "id": "i0Ra0_KzcJyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n************ Original ************\\n\")\n",
        "clasificador = SVC(C=10, degree=0, gamma=0.1, random_state=42)\n",
        "genera_graficas(conjunto_original, X_test, y_test, clasificador, \"Original\") \n",
        "\n",
        "print(\"\\n************ Sobremuestreo ************\\n\")\n",
        "clasificador = SVC(C=0.1, degree=6, gamma=1, random_state=42)\n",
        "genera_graficas(conjunto_sobremuestreo, X_test, y_test, clasificador,\"Sobremuestreo\") \n",
        "\n",
        "print(\"\\n************ SMOTE ************\\n\")\n",
        "clasificador = SVC(C=1, degree=0, gamma=0.1, random_state=42)\n",
        "genera_graficas(conjunto_smote, X_test, y_test, clasificador, \"SMOTE\") "
      ],
      "metadata": {
        "id": "TVze9TyecM1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes"
      ],
      "metadata": {
        "id": "3dIUcWgwEsK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n************ Original ************\\n\")\n",
        "clasificador =  GaussianNB(var_smoothing=0.0012328467394420659)\n",
        "genera_graficas(conjunto_original, X_test, y_test, clasificador, \"Original\") \n",
        "\n",
        "print(\"\\n************ Sobremuestreo ************\\n\")\n",
        "clasificador = GaussianNB(var_smoothing=0.0015199110829529332)\n",
        "genera_graficas(conjunto_sobremuestreo, X_test, y_test, clasificador,\"Sobremuestreo\") \n",
        "\n",
        "print(\"\\n************ SMOTE ************\\n\")\n",
        "clasificador = GaussianNB(var_smoothing=0.0003511191734215131)\n",
        "genera_graficas(conjunto_smote, X_test, y_test, clasificador, \"SMOTE\") "
      ],
      "metadata": {
        "id": "bIyVA9haEwbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Redes Neuronales"
      ],
      "metadata": {
        "id": "tjG9JnuiFyNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n************ Original ************\\n\")\n",
        "clasificador = MLPClassifier(activation='tanh', alpha=0.1, batch_size=2,\n",
        "                               hidden_layer_sizes=10, max_iter=20,\n",
        "                               random_state=42)\n",
        "genera_graficas(conjunto_original, X_test, y_test, clasificador, \"Original\") \n",
        "\n",
        "print(\"\\n************ Sobremuestreo ************\\n\")\n",
        "clasificador = MLPClassifier(activation='identity', alpha=0.01, batch_size=2,\n",
        "                               hidden_layer_sizes=50, max_iter=10,\n",
        "                               random_state=42)\n",
        "genera_graficas(conjunto_sobremuestreo, X_test, y_test, clasificador,\"Sobremuestreo\") \n",
        "\n",
        "print(\"\\n************ SMOTE ************\\n\")\n",
        "clasificador = MLPClassifier(activation='logistic', alpha=0.01, batch_size=2,\n",
        "                               hidden_layer_sizes=50, max_iter=20,\n",
        "                               random_state=42)\n",
        "genera_graficas(conjunto_smote, X_test, y_test, clasificador, \"SMOTE\") "
      ],
      "metadata": {
        "id": "RddWSujcF1i7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}