{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFM_Final_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BASE"
      ],
      "metadata": {
        "id": "SoB3t9Uzp75e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar paquetes que serán usados\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import linear_model, datasets\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from collections import Counter\n",
        "from warnings import filterwarnings\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import imblearn\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Definicion del color para las gráficas\n",
        "paleta=sns.color_palette(\"Blues_r\")\n",
        "\n",
        "# Lectura del conjunto de datos\n",
        "conjunto_datos = pd.read_csv(\"/content/drive/MyDrive/conjunto_1.csv\", sep=\";\", decimal=\",\")\n",
        "\n",
        "# Se renombran las columnas para que sean más descriptivas\n",
        "conjunto_datos.columns = [\"FS365\", \"FS450\", \"LDF35\",\"LDF42\",\"Clases\"]\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Función para la creacion del conjunto usando la técnica de sobremuestreo\n",
        "Parametros:   X_trains: matriz con el conjunto de entrenamiento\n",
        "              y_trains: vector con las clases objetivo\n",
        "Retorna: El conjunto con las clases balanceadas usando la técnica de sobremuestreo\n",
        "\"\"\"\n",
        "def genera_sobremuestreo(X_trains,y_trains):\n",
        "  conjunto_entrenamiento = pd.concat([X_trains, y_trains], axis=1) \n",
        "  cuenta_clases = conjunto_entrenamiento.Clases.value_counts()\n",
        "\n",
        "  cant_clase_0 = cuenta_clases[0]\n",
        "  cant_clase_1 = cuenta_clases[1]\n",
        "  cant_clase_2 = cuenta_clases[2]\n",
        "\n",
        "  conjunto_clase_0 = conjunto_entrenamiento[conjunto_entrenamiento['Clases'] == 0]\n",
        "  conjunto_clase_1 = conjunto_entrenamiento[conjunto_entrenamiento['Clases'] == 1]\n",
        "  conjunto_clase_2 = conjunto_entrenamiento[conjunto_entrenamiento['Clases'] == 2]\n",
        "\n",
        "  conjunto_clase_2_sm = conjunto_clase_2.sample(cant_clase_1, replace=True)\n",
        "  conjunto_clase_0_sm = conjunto_clase_0.sample(cant_clase_1, replace=True)\n",
        "\n",
        "  conjunto_sm = pd.concat([conjunto_clase_1, conjunto_clase_2_sm, conjunto_clase_0_sm], axis=0)\n",
        "  conjunto_sm.groupby('Clases').size()\n",
        "  return conjunto_sm\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Función para la creacion del conjunto usando la técnica de SMOTE\n",
        "Parametros:   X_trainm: matriz con el conjunto de entrenamiento\n",
        "              y_trainm: vector con las clases objetivo\n",
        "Retorna: El conjunto con las clases balanceadas usando la técnica de SMOTE\n",
        "\"\"\"\n",
        "def genera_smote(X_trainm,y_trainm):\n",
        "  sobre_muestreo_smote = SMOTE()\n",
        "  X, y = sobre_muestreo_smote.fit_resample(X_trainm, y_trainm)\n",
        "\n",
        "  conjunto_smo = pd.concat([X, y], axis=1)\n",
        "  conjunto_smo.groupby('Clases').size()\n",
        "  return conjunto_smo\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Función que realiza el entrenamiento con el conjunto original creado para tal fin\n",
        "Parametros:   algoritmo: es el modelo o algoritmos que se va a entrenar\n",
        "              parametros: hiperparámetros del modelo\n",
        "              X_traino, y_traino: conjunto de entrenamiento\n",
        "Salida por pantalla 1: los mejores hiperparámetros posterior al entrenamiento con GridSearchCV\n",
        "Salida por pantalla 2: puntuación generada por GridSearchCV\n",
        "\"\"\"\n",
        "def entrena_original(algoritmo, parametros, X_traino, y_traino):\n",
        "  print(\"\\n\\n  Conjunto Original\")\n",
        "  gs = GridSearchCV(algoritmo, parametros, cv=3, n_jobs=-1, verbose=True)\n",
        "  mejores_parametros = gs.fit(X_traino, y_traino)\n",
        "  print(mejores_parametros.best_estimator_)\n",
        "  print(mejores_parametros.best_score_)\n",
        "\n",
        "\"\"\"\n",
        "Función que realiza el entrenamiento con el conjunto de Sobremuestreo\n",
        "Parametros:   algoritmo: es el modelo o algoritmos que se va a entrenar\n",
        "              parametros: hiperparámetros del modelo\n",
        "              conjunto_sm: es el conjunto de entrenamiento, con las clases balanceadas \n",
        "                                      usando la técnica de sobremuestreo\n",
        "Salida por pantalla 1: los mejores hiperparámetros posterior al entrenamiento con GridSearchCV\n",
        "Salida por pantalla 2: puntuación generada por GridSearchCV\n",
        "\"\"\"\n",
        "def entrena_sobremuestreo(algoritmo, parametros, conjunto_sm):\n",
        "  print(\"\\n\\n  Conjunto Sobremuestreo\")\n",
        "  X_train_csm = conjunto_sm.drop('Clases', axis = 'columns')\n",
        "  y_train_csm = conjunto_sm['Clases']\n",
        "  gs = GridSearchCV(algoritmo, parametros, cv=3, n_jobs=-1, verbose=True)\n",
        "  mejores_parametros = gs.fit(X_train_csm, y_train_csm)\n",
        "  print(mejores_parametros.best_estimator_)\n",
        "  print(mejores_parametros.best_score_)\n",
        "\n",
        "\"\"\"\n",
        "Función que realiza el entrenamiento con el conjunto de SMOTE\n",
        "Parametros:   algoritmo: es el modelo o algoritmos que se va a entrenar\n",
        "              parametros: hiperparámetros del modelo\n",
        "              conjunto_smo: es el conjunto de entrenamiento, con las clases balanceadas \n",
        "                                      usando la técnica de SMOTE\n",
        "Salida por pantalla 1: los mejores hiperparámetros posterior al entrenamiento con GridSearchCV\n",
        "Salida por pantalla 2: puntuación generada por GridSearchCV\n",
        "\"\"\"\n",
        "def entrena_smote(algoritmo, parametros, conjunto_smo): \n",
        "  print(\"\\n\\n  Conjunto SMOTE \")\n",
        "  X_train_smo = conjunto_smo.drop('Clases', axis = 'columns')\n",
        "  y_train_smo = conjunto_smo['Clases']\n",
        "  gs = GridSearchCV(algoritmo, parametros, cv=3, n_jobs=-1, verbose=True)\n",
        "  mejores_parametros = gs.fit(X_train_smo, y_train_smo)\n",
        "  print(mejores_parametros.best_estimator_)\n",
        "  print(mejores_parametros.best_score_)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Función que realiza el reentrenamiento del modelo, lo evalúa y genera métricas\n",
        "Parametros:   conjunto_entrenamiento, X_test_x, y_test_x: conjuntos de entrenamiento y pruebas\n",
        "              algoritmo:  es el modelo que se va a entrenar, ya tiene los hiperparámetros la instanciar el clasificador\n",
        "              titulo:  hace referencia al tipo de set de entrenamiento, puede ser \"Original\", \"Sobremuestreo\" o \"SMOTE\"\n",
        "Salida por pantalla 1: métrica de precision\n",
        "Salida por pantalla 2: métrica de exactitud\n",
        "Salida por pantalla 3: informe con las principales métricas de clasificación.\n",
        "Salida por pantalla 4: matriz de confusión\n",
        "\"\"\"\n",
        "def genera_graficas(conjunto_entrenamiento, X_test_x, y_test_x, algoritmo, titulo):\n",
        "\n",
        "  X_train_x = conjunto_entrenamiento.drop('Clases', axis = 'columns')\n",
        "  y_train_x = conjunto_entrenamiento['Clases']\n",
        "\n",
        "  algoritmo.fit(X_train_x, y_train_x)\n",
        "  y_pred = algoritmo.predict(X_test_x)\n",
        "\n",
        "  print(\"Precision: \",precision_score(y_test_x, y_pred, average='weighted',zero_division=False))\n",
        "  print(\"Exactitud: \",accuracy_score(y_test_x, y_pred))\n",
        "\n",
        "  print(classification_report(y_test_x, y_pred,zero_division=False))\n",
        "  matriz_confusion = confusion_matrix(y_test_x, y_pred)\n",
        "\n",
        "  plt.figure(figsize=(7,7))\n",
        "  sns.heatmap(matriz_confusion, annot=True, cmap=paleta, linecolor='white', linewidths=0.1, square=True)\n",
        "  plt.title(titulo,size=16)\n",
        "  plt.xlabel('Etiqueta Predicha',size=14)\n",
        "  plt.ylabel('Etiqueta Verdadera',size=14)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "# División del conjunto de datos, en subconjuntos de entrenamiento y pruebas\n",
        "X_train, X_test, y_train, y_test = train_test_split(conjunto_datos.drop('Clases', axis = 'columns'), \n",
        "    conjunto_datos['Clases'],train_size= 0.7,random_state = 42,shuffle= True)\n",
        "\n",
        "# Une la matriz y vector de entrenamiento en un mismo conjunto\n",
        "conjunto_original = pd.concat([X_train, y_train], axis=1)\n",
        "\n",
        "# Generación de los conjuntos de entrenamiento, con las clases balanceadas usando _\n",
        "# las técnicas de Sobremuestreo y SMOTE\n",
        "conjunto_sobremuestreo = genera_sobremuestreo(X_train,y_train) \n",
        "conjunto_smote = genera_smote(X_train, y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "0qcOkJgwp9wV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento"
      ],
      "metadata": {
        "id": "pgoqwKS_Vlc1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regresión Logística"
      ],
      "metadata": {
        "id": "tew4er3Bwlb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Inicio el clasificador Regesion Logística\n",
        "clasificador_reglog = LogisticRegression(random_state=42)  \n",
        "\n",
        "# Se establecen los hiperparámetros del clasificador Regesion Logística\n",
        "hiper_parametros = {}                                     \n",
        "hiper_parametros['classifier__penalty'] = ['l1', 'l2']\n",
        "hiper_parametros['classifier__C'] = [10**-2, 10**-1, 10**0, 10**1, 10**2]\n",
        "hiper_parametros['classifier__solver'] = ['liblinear','lbfgs','newton-cg','sag','saga']\n",
        "hiper_parametros['classifier'] = [clasificador_reglog]\n",
        "pipeline = Pipeline([('classifier', clasificador_reglog)])\n",
        "filterwarnings('ignore')\n",
        "\n",
        "# Se realiza entrenamiento del modelo usando GridSearchCV\n",
        "entrena_original(pipeline, hiper_parametros, X_train, y_train)  \n",
        "entrena_sobremuestreo(pipeline, hiper_parametros, conjunto_sobremuestreo)  \n",
        "entrena_smote(pipeline, hiper_parametros, conjunto_smote)  \n"
      ],
      "metadata": {
        "id": "eMTTkUFvwqgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN"
      ],
      "metadata": {
        "id": "RTRvji_Fyh4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicio del clasificador K-Vecinos más Cercanos \n",
        "clasificador_veccer = KNeighborsClassifier()                \n",
        "\n",
        "# Se establecen los hiperparámetros del clasificador K-Vecinos más Cercanos   \n",
        "hiper_parametros = {}                                     \n",
        "hiper_parametros['classifier__n_neighbors'] = [5,10,20,50]\n",
        "hiper_parametros['classifier__weights'] = ['uniform', 'distance']\n",
        "hiper_parametros['classifier__leaf_size'] = [20,40,1]\n",
        "hiper_parametros['classifier__p'] = [1,2]\n",
        "hiper_parametros['classifier__algorithm'] = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "hiper_parametros['classifier__metric'] = ['minkowski', 'chebyshev']\n",
        "hiper_parametros['classifier'] = [clasificador_veccer]   \n",
        "pipeline = Pipeline([('classifier', clasificador_veccer)])\n",
        "filterwarnings('ignore')\n",
        "\n",
        "# Se realiza entrenamiento del modelo usando GridSearchCV\n",
        "entrena_original(pipeline, hiper_parametros, X_train, y_train)  \n",
        "entrena_sobremuestreo(pipeline, hiper_parametros, conjunto_sobremuestreo)  \n",
        "entrena_smote(pipeline, hiper_parametros, conjunto_smote)  "
      ],
      "metadata": {
        "id": "-_jTqHu5yiwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVMs"
      ],
      "metadata": {
        "id": "0v7YJ99dyjFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicio del clasificador Máquina de Soporte de Vectores\n",
        "clasificador_maqsop = SVC(random_state=42)              \n",
        "\n",
        "# Se establecen los hiperparámetros del clasificador Máquina de Soporte de Vectores\n",
        "hiper_parametros = {}                                      \n",
        "hiper_parametros['classifier__C'] = [0.1,1, 10, 100] \n",
        "hiper_parametros['classifier__gamma'] = [1,0.1,0.01,0.001]\n",
        "hiper_parametros['classifier__kernel'] = ['rbf', 'poly', 'sigmoid']\n",
        "hiper_parametros['classifier__degree'] = [0, 1, 2, 3, 4, 5, 6]\n",
        "hiper_parametros['classifier'] = [clasificador_maqsop]   \n",
        "pipeline = Pipeline([('classifier', clasificador_maqsop)])\n",
        "filterwarnings('ignore')\n",
        "\n",
        "# Se realiza entrenamiento del modelo usando GridSearchCV\n",
        "entrena_original(pipeline, hiper_parametros, X_train, y_train)  \n",
        "entrena_sobremuestreo(pipeline, hiper_parametros, conjunto_sobremuestreo)  \n",
        "entrena_smote(pipeline, hiper_parametros, conjunto_smote)  "
      ],
      "metadata": {
        "id": "tHX0Z1-QyjUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes"
      ],
      "metadata": {
        "id": "iNfY--GJyjiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicio del clasificador Naive Bayes\n",
        "clasificador_naibay = GaussianNB()                        \n",
        "\n",
        "# Se establecen los hiperparámetros del clasificador Naive Bayes\n",
        "hiper_parametros = {}                                      \n",
        "hiper_parametros['classifier__var_smoothing'] = np.logspace(0,-9, num=100)\n",
        "hiper_parametros['classifier'] = [clasificador_naibay]\n",
        "pipeline = Pipeline([('classifier', clasificador_naibay)])\n",
        "filterwarnings('ignore')\n",
        "\n",
        "# Se realiza entrenamiento del modelo usando GridSearchCV\n",
        "entrena_original(pipeline, hiper_parametros, X_train, y_train)  \n",
        "entrena_sobremuestreo(pipeline, hiper_parametros, conjunto_sobremuestreo)  \n",
        "entrena_smote(pipeline, hiper_parametros, conjunto_smote)  "
      ],
      "metadata": {
        "id": "f6cgOnYxyjtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Redes Neuronales"
      ],
      "metadata": {
        "id": "-rsnJU_Pyj6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicio del clasificador Redes Neuronales\n",
        "clasificador_redneu = MLPClassifier(random_state=42)  \n",
        "\n",
        "# Se establecen los hiperparámetros del clasificador Redes Neuronales\n",
        "hiper_parametros = {}                                     \n",
        "hiper_parametros['classifier__alpha'] = [0.1, 0.01, 0.001]\n",
        "hiper_parametros['classifier__max_iter'] = [5,10,20]\n",
        "hiper_parametros['classifier__batch_size'] = [2,5,20]\n",
        "hiper_parametros['classifier__activation'] = ['identity', 'logistic', 'tanh', 'relu']\n",
        "hiper_parametros['classifier__hidden_layer_sizes'] = [1,3,5,10,50]  \n",
        "hiper_parametros['classifier'] = [clasificador_redneu]\n",
        "pipeline = Pipeline([('classifier', clasificador_redneu)])\n",
        "filterwarnings('ignore')\n",
        "\n",
        "# Se realiza entrenamiento del modelo usando GridSearchCV\n",
        "entrena_original(pipeline, hiper_parametros, X_train, y_train)  \n",
        "entrena_sobremuestreo(pipeline, hiper_parametros, conjunto_sobremuestreo)  \n",
        "entrena_smote(pipeline, hiper_parametros, conjunto_smote)   "
      ],
      "metadata": {
        "id": "LTOXW8xxykFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reentrenamiento y evaluación de modelos"
      ],
      "metadata": {
        "id": "SU3Fez3V7UMu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El código que se encuentra en la parte inferior, cuenta con los hiperparámetros que mejores resultados proporcionaron al realizar el entrenamiento con GridSearchCV. Es posible que haya una variación, y se debe revisar las salidas por pantalla de la sección \"Entrenamiento\"."
      ],
      "metadata": {
        "id": "iryvLdeWUhbM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regresión Logística"
      ],
      "metadata": {
        "id": "Z9TpxpW1CIpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n************ Original ************\\n\")\n",
        "clasificador = LogisticRegression(C=10, penalty='l1', random_state=42,solver='liblinear')\n",
        "genera_graficas(conjunto_original, X_test, y_test, clasificador, \"Original\") \n",
        "\n",
        "print(\"\\n************ Sobremuestreo ************\\n\")\n",
        "clasificador = LogisticRegression(C=1, random_state=42)\n",
        "genera_graficas(conjunto_sobremuestreo, X_test, y_test, clasificador,\"Sobremuestreo\") \n",
        "\n",
        "print(\"\\n************ SMOTE ************\\n\")\n",
        "clasificador = LogisticRegression(C=10, random_state=42)\n",
        "genera_graficas(conjunto_smote, X_test, y_test, clasificador, \"SMOTE\") "
      ],
      "metadata": {
        "id": "hyuQtJhT7p1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN"
      ],
      "metadata": {
        "id": "jQBjyepZCAgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n************ Original ************\\n\")\n",
        "clasificador = KNeighborsClassifier(leaf_size=20, n_neighbors=10, p=1)\n",
        "genera_graficas(conjunto_original, X_test, y_test, clasificador, \"Original\") \n",
        "\n",
        "print(\"\\n************ Sobremuestreo ************\\n\")\n",
        "clasificador = KNeighborsClassifier(leaf_size=20, n_neighbors=10, p=1, weights='distance')\n",
        "genera_graficas(conjunto_sobremuestreo, X_test, y_test, clasificador,\"Sobremuestreo\") \n",
        "\n",
        "print(\"\\n************ SMOTE ************\\n\")\n",
        "clasificador = KNeighborsClassifier(leaf_size=20, n_neighbors=10, p=1, weights='distance')\n",
        "genera_graficas(conjunto_smote, X_test, y_test, clasificador, \"SMOTE\") "
      ],
      "metadata": {
        "id": "WtTCF31jCRfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVMs"
      ],
      "metadata": {
        "id": "i0Ra0_KzcJyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n************ Original ************\\n\")\n",
        "clasificador = GaussianNB(var_smoothing=0.0012328467394420659)\n",
        "genera_graficas(conjunto_original, X_test, y_test, clasificador, \"Original\") \n",
        "\n",
        "print(\"\\n************ Sobremuestreo ************\\n\")\n",
        "clasificador = GaussianNB(var_smoothing=0.0023101297000831605)\n",
        "genera_graficas(conjunto_sobremuestreo, X_test, y_test, clasificador,\"Sobremuestreo\") \n",
        "\n",
        "print(\"\\n************ SMOTE ************\\n\")\n",
        "clasificador = GaussianNB(var_smoothing=0.0008111308307896872)\n",
        "genera_graficas(conjunto_smote, X_test, y_test, clasificador, \"SMOTE\") "
      ],
      "metadata": {
        "id": "TVze9TyecM1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes"
      ],
      "metadata": {
        "id": "3dIUcWgwEsK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n************ Original ************\\n\")\n",
        "clasificador = SVC(C=10, degree=0, gamma=0.1, random_state=42)\n",
        "genera_graficas(conjunto_original, X_test, y_test, clasificador, \"Original\") \n",
        "\n",
        "print(\"\\n************ Sobremuestreo ************\\n\")\n",
        "clasificador = SVC(C=10, degree=0, gamma=1, random_state=42)\n",
        "genera_graficas(conjunto_sobremuestreo, X_test, y_test, clasificador,\"Sobremuestreo\") \n",
        "\n",
        "print(\"\\n************ SMOTE ************\\n\")\n",
        "clasificador = SVC(C=1, degree=0, gamma=0.1, random_state=42)\n",
        "genera_graficas(conjunto_smote, X_test, y_test, clasificador, \"SMOTE\") "
      ],
      "metadata": {
        "id": "bIyVA9haEwbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Redes Neuronales"
      ],
      "metadata": {
        "id": "tjG9JnuiFyNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n************ Original ************\\n\")\n",
        "clasificador = MLPClassifier(activation='tanh', alpha=0.1, batch_size=2,\n",
        "                               hidden_layer_sizes=10, max_iter=20,\n",
        "                               random_state=42)\n",
        "genera_graficas(conjunto_original, X_test, y_test, clasificador, \"Original\") \n",
        "\n",
        "print(\"\\n************ Sobremuestreo ************\\n\")\n",
        "clasificador = MLPClassifier(activation='identity', alpha=0.01, batch_size=2,\n",
        "                               hidden_layer_sizes=50, max_iter=10,\n",
        "                               random_state=42)\n",
        "genera_graficas(conjunto_sobremuestreo, X_test, y_test, clasificador,\"Sobremuestreo\") \n",
        "\n",
        "print(\"\\n************ SMOTE ************\\n\")\n",
        "clasificador = MLPClassifier(activation='logistic', alpha=0.01, batch_size=2,\n",
        "                               hidden_layer_sizes=50, max_iter=20,\n",
        "                               random_state=42)\n",
        "genera_graficas(conjunto_smote, X_test, y_test, clasificador, \"SMOTE\") "
      ],
      "metadata": {
        "id": "RddWSujcF1i7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}